


  





  

<!DOCTYPE html>
<html lang="en-us">
  <head>
    
    <meta charset="UTF-8">
    <meta name="viewport" content="width=device-width, initial-scale=1">
    <meta name="generator" content="Hugo 0.54.0">
    <meta name="theme" content="Tranquilpeak 0.3.1-BETA">
    <title>Em</title>
    <meta name="author" content="Josh Hancock">
    <meta name="keywords" content="">

    <link rel="icon" href="/favicon.png">
    
      <link rel="alternate" type="application/rss+xml" title="RSS" href="/tags/em/index.xml">
    

    
    <meta name="description" content="Josh Hancock">
    <meta property="og:description" content="Josh Hancock">
    <meta property="og:type" content="blog">
    <meta property="og:title" content="Em">
    <meta property="og:url" content="/tags/em/">
    <meta property="og:site_name" content="Josh Hancock&#39;s Personal Site">
    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Josh Hancock&#39;s Personal Site">
    <meta name="twitter:description" content="Josh Hancock">
    
    

    
    

    
      <meta property="og:image" content="https://github.com/joshuahancock/joshuahancock.github.io/blob/master/images/avatar.jpg?raw=true">
    

    
    
    

    

    
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/font-awesome/4.7.0/css/font-awesome.min.css" />
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.css" />
    <link rel="stylesheet" href="//cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.css" />
    
    
    <link rel="stylesheet" href="/css/style-u6mk0ojoywresbx8iepslrmmhl4stuhrsxuwhkpwrkrx7mryjcaimasnk4pi.min.css" />
    
    

    
      
    
    
  </head>

  <body>
    <div id="blog">
      <header id="header" data-behavior="1">
  <i id="btn-open-sidebar" class="fa fa-lg fa-bars"></i>
  <div class="header-title">
    <a class="header-title-link" href="/">Josh Hancock&#39;s Personal Site</a>
  </div>
  
    
      <a class="header-right-picture "
         href="/#about">
    
    
    
      
        <img class="header-picture" src="https://github.com/joshuahancock/joshuahancock.github.io/blob/master/images/avatar.jpg?raw=true" alt="Author&#39;s picture" />
      
    
    </a>
  
</header>

      <nav id="sidebar" data-behavior="1">
  <div class="sidebar-container">
    
      <div class="sidebar-profile">
        <a href="/#about">
          <img class="sidebar-profile-picture" src="https://github.com/joshuahancock/joshuahancock.github.io/blob/master/images/avatar.jpg?raw=true" alt="Author&#39;s picture" />
        </a>
        <h4 class="sidebar-profile-name">Josh Hancock</h4>
        
          <h5 class="sidebar-profile-bio">info@joshuahancock.org</h5>
        
      </div>
    
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/categories">
    
      <i class="sidebar-button-icon fa fa-lg fa-bookmark"></i>
      
      <span class="sidebar-button-desc">Categories</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/tags">
    
      <i class="sidebar-button-icon fa fa-lg fa-tags"></i>
      
      <span class="sidebar-button-desc">Tags</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/archives">
    
      <i class="sidebar-button-icon fa fa-lg fa-archive"></i>
      
      <span class="sidebar-button-desc">Archives</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/#about">
    
      <i class="sidebar-button-icon fa fa-lg fa-question"></i>
      
      <span class="sidebar-button-desc">About</span>
    </a>
  </li>

  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/">
    
      <i class="sidebar-button-icon fa fa-lg fa-home"></i>
      
      <span class="sidebar-button-desc">Home</span>
    </a>
  </li>

    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="https://github.com/joshuahancock">
    
      <i class="sidebar-button-icon fa fa-lg fa-github"></i>
      
      <span class="sidebar-button-desc">GitHub</span>
    </a>
  </li>

    </ul>
    <ul class="sidebar-buttons">
      
  <li class="sidebar-button">
    
      <a class="sidebar-button-link " href="/index.xml">
    
      <i class="sidebar-button-icon fa fa-lg fa-rss"></i>
      
      <span class="sidebar-button-desc">RSS</span>
    </a>
  </li>

    </ul>
  </div>
</nav>

      
        

      
      <div id="main" data-behavior="1"
        class="
               hasCoverMetaIn
               ">
        
          <section class="postShorten-group main-content-wrap">
            
            
              
  
    
  


  

<article class="postShorten postShorten--thumbnailimg-bottom" itemscope itemType="http://schema.org/BlogPosting">
  <div class="postShorten-wrap">
    
    <div class="postShorten-header">
      <h1 class="postShorten-title" itemprop="headline">
        <a class="link-unstyled" href="/2017/06/classifying-handwritten-digits-using-em-and-pca/">
          Classifying Handwritten Digits Using EM and PCA
        </a>
      </h1>
      <div class="postShorten-meta post-meta">
  
    <time itemprop="datePublished" datetime="2017-06-03T00:00:00Z">
      
  June 3, 2017

    </time>
  
  
  
  
    <span>in</span>
    
      <a class="category-link" href="/categories/machine-learning">machine learning</a>
    
  


</div>

    </div>
    <div class="postShorten-excerpt" itemprop="articleBody">
      <p>
        <p>In this post, we’ll take the <a href="http://archive.ics.uci.edu/ml/datasets/semeion+handwritten+digit">Semeion Handwritten Digits</a> data set and cluster the handwritten digits data using the EM algorithm with a principle components step within each maximization.
First, we’ll read in the data, load the additional libraries, and create our initial data table.
library(&quot;mvtnorm&quot;)
library(&quot;data.table&quot;)</p>

<h1 id="reading-data-and-convert-to-data-table">Reading data and convert to data table</h1>

<p>setwd(&quot;C:/Users/Josh/Documents/GitHub/joshuahancock.github.io/data_sets/&quot;)
data &lt;- fread(&quot;C:/Users/Josh/Documents/GitHub/joshuahancock.github.io/data_sets/semeion.csv&quot;, header = FALSE)
x &lt;- data[, 1:256]
Each row of the data represents one handwritten digit, which were digitally scanned and stretched into a 16x16 pixel box.</p>

        <br>
        <a href="/2017/06/classifying-handwritten-digits-using-em-and-pca/" class="postShorten-excerpt_link link">Continue reading</a>
        
      </p>
    </div>
  </div>
  
    <a href="/2017/06/classifying-handwritten-digits-using-em-and-pca/">
      <div class="postShorten-thumbnailimg">
        <img alt="" itemprop="image" src="images/heat_plot_large.jpeg"/>
      </div>
    </a>
  
</article>

            
            

          </section>
        
        <footer id="footer" class="main-content-wrap">
<script type="text/javascript"
  src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.1/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
</script>


  <span class="copyrights">
    &copy; 2019 Josh Hancock. All Rights Reserved
  </span>
</footer>

      </div>
    </div>
    
    <div id="about">
  <div id="about-card">
    <div id="about-btn-close">
      <i class="fa fa-remove"></i>
    </div>
    
      <img id="about-card-picture" src="https://github.com/joshuahancock/joshuahancock.github.io/blob/master/images/avatar.jpg?raw=true" alt="Author&#39;s picture" />
    
    <h4 id="about-card-name">Josh Hancock</h4>
    
      <div id="about-card-bio">info@joshuahancock.org</div>
    
    
      <div id="about-card-job">
        <i class="fa fa-briefcase"></i>
        <br/>
        Senior Data Scientist @ Nike
      </div>
    
    
      <div id="about-card-location">
        <i class="fa fa-map-marker"></i>
        <br/>
        Portland, OR
      </div>
    
  </div>
</div>

    <div id="algolia-search-modal" class="modal-container">
  <div class="modal">
    <div class="modal-header">
      <span class="close-button"><i class="fa fa-close"></i></span>
      <a href="https://algolia.com" target="_blank" class="searchby-algolia text-color-light link-unstyled">
        <span class="searchby-algolia-text text-color-light text-small">by</span>
        <img class="searchby-algolia-logo" src="https://www.algolia.com/static_assets/images/press/downloads/algolia-light.svg">
      </a>
      <i class="search-icon fa fa-search"></i>
      <form id="algolia-search-form">
        <input type="text" id="algolia-search-input" name="search"
          class="form-control input--large search-input" placeholder="Search" />
      </form>
    </div>
    <div class="modal-body">
      <div class="no-result text-color-light text-center">no post found</div>
      <div class="results">
        
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2019/02/test-post/">
                <h3 class="media-heading">Test Post</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Feb 2, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather"></div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2017/06/classifying-handwritten-digits-using-em-and-pca/">
                <h3 class="media-heading">Classifying Handwritten Digits Using EM and PCA</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Jun 6, 2017
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">In this post, we’ll take the [Semeion Handwritten Digits] (http://archive.ics.uci.edu/ml/datasets/semeion+handwritten+digit) data set and cluster the handwritten digits data using the EM algorithm with a principle components step within each maximization.
First, we’ll read in the data, load the additional libraries, and create our initial data table.
library(&quot;mvtnorm&quot;)library(&quot;data.table&quot;)# Reading data and convert to data tablesetwd(&quot;C:/Users/Josh/Documents/GitHub/joshuahancock.github.io/data_sets/&quot;)data &lt;- fread(&quot;C:/Users/Josh/Documents/GitHub/joshuahancock.github.io/data_sets/semeion.csv&quot;, header = FALSE)x &lt;- data[, 1:256]Each row of the data represents one handwritten digit, which were digitally scanned and stretched into a 16x16 pixel box.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2017/06/using-regression-analysis-to-predict-mlb-attendance/">
                <h3 class="media-heading">Using Regression Analysis to Predict MLB Attendance</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Jun 6, 2017
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather">The standard MLB season is 162 games long and each team typically plays 81 games at home and 81 games in the stadiums of the opposing teams. Using data from historical MLB seasons, we can build a model to predict the total attendance at the 81 home games for each team. In many business applications, it’s of particualr interest to stakeholders to understand which factors influence the revenue-creating side of the business.</div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/2017/06/using-regression-analysis-to-predict-mlb-attendance/">
                <h3 class="media-heading">Using Regression Analysis to Predict MLB Attendance</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Jun 6, 2017
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather"><p>The standard MLB season is 162 games long and each team typically plays 81 games at home and 81 games in the stadiums of the opposing teams. Using data from historical MLB seasons, we can build a model to predict the total attendance at the 81 home games for each team. In many business applications, it&rsquo;s of particualr interest to stakeholders to understand which factors influence the revenue-creating side of the business. For this reason, we&rsquo;ll choose to use a linear regression model, which may fall short of deep-learning models when it comes to predictive power, but will provide an output that is interpritable and may allow for a better understaning of the business as a whole.</p>

<p>First, we&rsquo;ll obtain and clean data. Attendance can be influenced by many factors beyond the playing field, so it will be important to include data on both team performance factors and the demographics of the city and fan base for each team. For team data, we can use <a href="www.baseballreference.com">Baseball Reference</a> to grab results between 2006 and 2014 for each of the 30 teams, giving us 270 observations. In addition to the win/loss records of each team, we have home attendance, wins, payroll, stadium name, stadium capacity, stadium age, number of years a team has been in a city, playoff appearances for each team, the number of all-stars for each team, the number of home-runs hit by each team, and the number of professional sports teams in in each city for each observation.</p>

<p>Using publically available demographic data for each city, we can also include the number of people, the number of households, and the median income for various drive times (15, 30, 45, and 60 minutes) from each stadium. We then imported the data into R and inspected it for any obvious problems (graphically and using the <em>summary</em> command).</p>

<pre><code class="language-r,">require(faraway)
require(car)
require(leaps)
require(ggplot2)
</code></pre>

<pre><code class="language-r">mlbattendance_final = read.csv(&quot;mlbattendance_final.csv&quot;, header = TRUE)
attach(mlbattendance_final)
summary(mlbattendance_final)
</code></pre>

<p>reserve 10% of our data for testing purposes before starting our analysis.</p>

<pre><code class="language-r,echo=FALSE">testdata &lt;- mlbattendance_final[(seq(from=10, to=nrow(mlbattendance_final), by=10)),]
traindata &lt;- mlbattendance_final[-(seq(from=10, to=nrow(mlbattendance_final), by=10)),]
</code></pre>

<pre><code class="language-r">nrow(testdata)
nrow(traindata)
</code></pre>

<p>We begin our analysis with 243 observations x 27 variables (including observation names) for the training data set.We started our analysis with a base model:</p>

<pre><code class="language-r">basemod &lt;- lm(nextAttend ~ currentAttend + currentW + priorW + X.capacity + payrollM + 
                stadiumCap + stadiumAge + yearsInCity + playoffsBin + proTeams + 
                allstars + hrs + pop15 + pop30 + pop45 + pop60 + households15 + 
                households30 + households45 + households60 + medInc15 + medInc30 + medInc45 +
                medInc60,data=traindata)
</code></pre>

<p>Note: See Appendix A for an explanation of the data and variable names</p>

<p>Initially, we suspected a strong correlation between many variables in our data set. We started by looking at the correlation matrix (See Appendix B).</p>

<p>There were many strong correlations, especially with the demographic data. We decided to build a different base model for each level of drive time (15,30,45,60) data to determine which one has the most significance in the current model:</p>

<pre><code class="language-r">lmod15&lt;-lm(nextAttend ~ currentAttend + currentW + priorW + X.capacity + payrollM + 
             stadiumCap + stadiumAge + yearsInCity + playoffsBin + proTeams + allstars + 
             hrs + pop15 + households15 + medInc15,data=traindata)


lmod30&lt;-lm(nextAttend ~ currentAttend + currentW + priorW + X.capacity + payrollM + 
             stadiumCap + stadiumAge + yearsInCity + playoffsBin + proTeams + allstars + 
             hrs + pop30 + households30 + medInc30,data=traindata)


lmod45&lt;-lm(nextAttend ~ currentAttend + currentW + priorW + X.capacity + payrollM + 
             stadiumCap + stadiumAge + yearsInCity + playoffsBin + proTeams + allstars + 
             hrs + pop45 + households45 + medInc45,data=traindata)


lmod60&lt;-lm(nextAttend ~ currentAttend + currentW + priorW + X.capacity + payrollM + 
             stadiumCap + stadiumAge + yearsInCity + playoffsBin + proTeams + allstars + 
             hrs + pop60 + households60 + medInc60,data=traindata)

</code></pre>

<p>All models were similar in adjusted $r^2$, so we selected the 60-minute model, which seemed to have the most significance in the individual drive-time variables. Even after selecting a single level of demographic data, there still seemed to be issues with correlated predictors, so we decided to view the variance inflation factor(VIF) for the 60-minute model:</p>

<pre><code class="language-r,include=FALSE">x2 &lt;- model.matrix(lmod60)[,-1]
round(cor(x2[,1:15]),2)
</code></pre>

<pre><code class="language-r">vif(lmod60)
</code></pre>

<p>There seems to be two issues that need to be addressed. There is a very large VIF for currentAttend, X.capacity, pop60, and households60. stadiumCap also has a large VIF, but we will choose to address that after addressing the higher values. We start by removing X.capacity and households60.</p>

<pre><code class="language-r">lmod &lt;- lm(nextAttend ~ currentAttend + currentW + priorW + payrollM + stadiumCap + stadiumAge + yearsInCity + playoffsBin + proTeams + allstars + hrs + pop60 + medInc60,data=traindata)
vif(lmod)
</code></pre>

<p>All the VIF levels are under 10 (including <em>stadiumCap</em>), so we now move to graphically checking the variance (see Appendix C for plot).</p>

<p>From the plot we can safely assess that the variance appears to be constant and no further investigation is needed.
Next, we will check normality assumptions (see Appendix C for plot).</p>

<p>The qqplot appears to show that the data is short-tailed, which is acceptable. We can conclude that no transformation of our model is needed because there doesn&rsquo;t appear to be any problems with variance or linearity.</p>

<p>Next we will check for high leverages in our data:</p>

<pre><code class="language-r">hatv &lt;- hatvalues(lmod)
threshold &lt;- (2*14)/243
hatv_true &lt;- hatv&gt;threshold
which(hatv_true, useNames = TRUE)
</code></pre>

<p>There are a few observations that have a higher leverage than the $\textit{2p/n}$ ratio of 0.1037 (see Appendix C for plot). At this point we decide that they were not severe enough to immediately remove and should be assessed in presence of other tests. Next, we looked for outliers using the Bonferoni Correction:</p>

<pre><code class="language-r">stud &lt;- rstudent(lmod)
</code></pre>

<p>This gives us studentized residuals. Now, calculate the Bonferoni critical value:</p>

<pre><code class="language-r">bonf &lt;- qt((0.05/243*2),232)
abs_bonf &lt;- abs(bonf)
abs_stud &lt;- abs(stud)
bonf_points &lt;- abs_stud &gt; abs_bonf
abs_bonf
</code></pre>

<p>As we an see, there is one observation that exceeds the Bonferoni critical value. Because the data set is fairly large (n=243), we are not overly concerned with outliers. In order to test for influential points, we calculated the Cooks Distance for the data.</p>

<pre><code class="language-r">cook &lt;- cooks.distance(lmod)
</code></pre>

<p>We then plotted the half normal plot of Cooks Distance and use the $4/(n-p-1)$ rule of thumb to check for any influential points in the data (see Appendix C for plot). From this we identified 12 points that appear to be influential points. We then removed those points and moved on with our diagnostics.</p>

<pre><code class="language-r">newtrain &lt;- subset(traindata, cook &lt; 0.01754)
</code></pre>

<pre><code class="language-r,">lmod &lt;- lm(nextAttend ~ currentAttend + currentW + priorW + payrollM + stadiumCap + stadiumAge + yearsInCity + playoffsBin + proTeams + allstars + hrs + pop60 + medInc60,data=newtrain)
lmod2 &lt;- lm(nextAttend ~ currentW + priorW + payrollM + stadiumCap + stadiumAge + yearsInCity + playoffsBin + proTeams + allstars + hrs + pop60 + medInc60, data=traindata)
</code></pre>

<p>Confident that our data and model assumptions are sound, we chose to move on to the shrinkage phase of the diagnostics.</p>

<pre><code class="language-r">b &lt;- regsubsets((nextAttend ~ currentAttend + currentW + priorW + payrollM + stadiumCap + stadiumAge + yearsInCity + playoffsBin + proTeams + allstars + hrs + pop60 + medInc60), data=newtrain, nvmax=14)
rs &lt;- summary(b)
</code></pre>

<p>Note: See Appendix E for predictor logic matrix</p>

<pre><code class="language-r">AIC &lt;- 231*log(rs$rss/231) + (2:14)*2
which.min(AIC)
</code></pre>

<p><em>AIC</em> suggests the nine predictor model (see Appendix C for plot). Next, we&rsquo;ll look at the <em>Mallows CP</em> criterion (see Appendix C for plot). <em>Mallows CP</em> suggests a model with ten predictors. Next, we looked at <em>adjusted $r^2$</em>.</p>

<pre><code class="language-r">which.max(rs$adjr2)
</code></pre>

<p><em>Adjusted $r^2$</em> suggests 10 predictors. As we did further analysis to decide on a final model, something became clear. The model that we were considering had one predictor that was much more significant than the others: <em>currentAttend</em>. Including this predictor in our model gave us a higher degree of accuracy, which is desirable in a prediction model. However, this predictor appeared to already contain much of the information we sought to include in our model by using additional variables and would possibly limit the amount of inference that could be achieved compared to a model that uses more predictors. We decided to branch our model into two different versions: one with <em>currentAttend</em> and one without. We checked the Cooks Distances for this model with the original training data set and found that slightly fewer points seemed to be influential, so we made a separate subset for the second model.</p>

<pre><code class="language-r">cook2 &lt;- cooks.distance(lmod2)
newtrain2 &lt;- subset(traindata, cook2 &lt; 0.01746)
</code></pre>

<p>Here is the second version of the model:</p>

<pre><code class="language-r">lmod2 &lt;- lm(nextAttend ~ currentW + priorW + payrollM + stadiumCap + stadiumAge + yearsInCity + playoffsBin + proTeams + allstars + hrs + pop60 + medInc60, data=newtrain2)
</code></pre>

<p>After running the same diagnostics on the second model as we did on the original, <em>AIC</em> suggested ten predictors, <em>CP</em> suggested 11 predictors, and <em>adjusted $r^2$</em> suggested 11.</p>

<p>After considering the suggested number of predictors from each criterion, we removed predictors using the logic matrix and came up with the following models:</p>

<pre><code class="language-r">final_lmod &lt;- lm(nextAttend ~ currentAttend + currentW + priorW + payrollM + stadiumCap + stadiumAge + yearsInCity + proTeams,data=newtrain)

final_lmod2 &lt;- lm(nextAttend ~ hrs + stadiumAge + pop60 + priorW + playoffsBin + medInc60 + payrollM + currentW + yearsInCity + stadiumCap, data = newtrain2)


</code></pre>

<p>Taking a look at the coefficients, we decided to scale <em>stadiumCap</em> to the same units as the attendance numbers.</p>

<pre><code class="language-r">
final_lmod &lt;- lm(nextAttend ~ currentAttend + currentW + priorW + payrollM + I(stadiumCap/1000) + stadiumAge + yearsInCity + proTeams,data=newtrain)

final_lmod2 &lt;- lm(nextAttend ~ hrs + stadiumAge + pop60 + priorW + playoffsBin + medInc60 + payrollM + currentW + yearsInCity + I(stadiumCap), data = newtrain2)

sumary(final_lmod)
sumary(final_lmod2)
</code></pre>

<p>For an interpretation of the coefficients, we start with the model containing <em>currentAttend</em>:</p>

<p><strong>intercept</strong>: no meaningful interpretation (not possible to have negative attendance)<br />
<strong>currentAttend</strong>: for every 1000 people that attend in the current year, 926 people can be expected to attend next year (ceteris paribus)<br />
<strong>currentW</strong>: for each additional game a team wins, we can expect and additional 7780 people to attend the next year (ceteris paribus)<br />
<strong>priorW</strong>: for each game a team won last season, the expected attendance will drop by 3459 people in two seasons(ceteris paribus). This is counterintuitive and may be due to a correction effect resulting from other predictors<br />
<strong>payrollM</strong>: for each additional million dollars a team spends on payroll, the attendance of the next season can be expected to drop by 2189 (ceteris paribus). This is also counterintuitive and could also be a correcting effect.<br />
<strong>stadiumCap</strong>: for each additional 1000 seats in capacity, the attendance can be expected to increase by 9281 people over the course of a season(ceteris paribus)<br />
<strong>stadiumAge</strong>: for each additional year in stadium age, the attendance can be expected to increase by 1007(ceteris paribus)<br />
<strong>yearsInCity</strong>: for each additional year a franchise has been located in its current city, we can expect an additional 705 people to attend (ceteris paribus)<br />
<strong>proTeams</strong>: for every additional professional team in the metro area, attendance will increase by 13101 per season (ceteris paribus)</p>

<p>There are a few differences in the coefficients between the two models. Most notably, all of the coefficients became positive (except for the intercept and <em>hrs</em>) in the second model. This leads us to believe that the <em>currentAttend</em> data was a very powerful vacuum, so to speak, and all the information that is sucked up by and contained inside of it needs to be corrected by other covariates contained in the model. In the absence of <em>currentAttend</em>, many of the other predictors&rsquo; significance levels increased as they absorbed some of the significance abandoned by <em>currentAttend</em>. Additionally, <em>hrs</em>, <em>pop60</em>, and <em>medInc60</em> are included in the model and are significant at the 0.15, 0.10, and 0.01 levels, respectively.</p>

<p>We decided to use both models to fit values to the test data. First, we define a function that calculates <em>rmse</em>:</p>

<pre><code class="language-r">rmse &lt;- function(x,y)sqrt(mean((x-y)^2))
</code></pre>

<p>Now we will compare the two models.</p>

<p>The model with <em>currentAttend</em>:</p>

<pre><code class="language-r">rmse(fitted(final_lmod),newtrain$nextAttend)
rmse(predict(final_lmod,testdata),testdata$nextAttend)
</code></pre>

<p>The model without <em>currentAttend</em>:</p>

<pre><code class="language-r">rmse(fitted(final_lmod2),newtrain2$nextAttend)
rmse(predict(final_lmod2,testdata),testdata$nextAttend)
</code></pre>

<p>As we expected, the model that includes <em>currentAttend</em> has the lower <em>rmse</em> value for the train and test cases.</p>

<p>Graphically:</p>

<pre><code class="language-r,echo=FALSE,">attach(testdata)
testvals &lt;- predict(final_lmod,testdata)
plot(currentAttend,testvals, ylab = &quot;Predicted Values for Test Data&quot;, xlab=&quot;Actual Values from Test Data&quot;, main = &quot;Model With currentAttend&quot;)
abline(0,1)
testvals &lt;- predict(final_lmod2,testdata)
plot(currentAttend,testvals, ylab = &quot;Predicted Values for Test Data&quot;, xlab=&quot;Actual Values from Test Data&quot;, main = &quot;Model without currentAttend&quot;)
abline(0,1)
</code></pre></div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
          <div class="media">
            
            <div class="media-body">
              <a class="link-unstyled" href="/post/">
                <h3 class="media-heading">Posts</h3>
              </a>
              <span class="media-meta">
                <span class="media-date text-small">
                  Feb 2, 2019
                </span>
              </span>
              <div class="media-content hide-xs font-merryweather"></div>
            </div>
            <div style="clear:both;"></div>
            <hr>
          </div>
        
      </div>
    </div>
    <div class="modal-footer">
      <p class="results-count text-medium"
         data-message-zero="no post found"
         data-message-one="1 post found"
         data-message-other="{n} posts found">
         5 posts found
      </p>
    </div>
  </div>
</div>
    
  
    
    <div id="cover" style="background-image:url('images/placeholder_optimized.jpg');"></div>
  


    
<script src="//cdnjs.cloudflare.com/ajax/libs/jquery/2.1.3/jquery.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/highlight.js/9.8.0/highlight.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/jquery.fancybox.min.js"></script>
<script src="//cdnjs.cloudflare.com/ajax/libs/fancybox/2.1.4/helpers/jquery.fancybox-thumbs.min.js"></script>


<script src="/js/script-wl33z0n6ocaypepiqrazthtivfrliqijej4rq8ek8gvrv1awftmgjuv8k4zc.min.js"></script>

<script>
$(document).ready(function() {
  hljs.configure({ classPrefix: '', useBR: false });
  $('pre.code-highlight').each(function(i, block) {
    var code = "";
    hljs.highlightAuto(block.innerText).value.split(/\r\n|\r|\n/).forEach(function(line) {
      code += "<span class=\"line\">" + line + "</span><br>";
    });
    if (code.length > 0) {
      block.innerHTML = code;  
    }
  });
  $('pre > code').each(function(i, block) {
    $(this).addClass('codeblock');
    hljs.highlightBlock(block);
  });
});
</script>





    
  </body>
</html>

